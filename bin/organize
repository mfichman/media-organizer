#!/bin/env python

import exifread
import pathlib
import argparse
import peewee
import datetime
import hashlib
import glob
import os
import ffmpeg
import hachoir.parser
import hachoir.metadata
import hachoir.core
import re
import humanize
import itertools
import PIL.Image
import PIL.ExifTags
import json
import base64
import multiprocessing

db = peewee.SqliteDatabase('photos.db', pragmas={'journal_mode': 'wal'})

class Media(peewee.Model):
    class Meta:
        database = db
        indexes = (
            (('extension', 'stem'), False),
        )

    name = peewee.CharField()
    stem = peewee.CharField()
    extension = peewee.CharField()
    path = peewee.CharField(index=True)
    digest = peewee.CharField(index=True)
    size = peewee.BigIntegerField()
    metadata = peewee.CharField()
    created_at = peewee.DateTimeField(default=datetime.datetime.now)
    updated_at = peewee.DateTimeField(default=datetime.datetime.now)
    taken_at = peewee.DateTimeField(index=True)
    organized_at = peewee.DateTimeField(null=True)
    source = peewee.CharField(unique=True)

class Photo(Media):
    pass

def parse_digest(path):
    sha = hashlib.sha256()
    buf = bytearray(32768)
    mv = memoryview(buf)

    with open(path, 'rb', buffering=0) as fd:
        for offset in iter(lambda: fd.readinto(mv), 0):
            sha.update(mv[:offset])

    return sha.hexdigest()

def parse_taken_at(metadata, path, stat):
    return (
        parse_timestamp_with_exif(path, metadata, 'DateTimeOriginal', 'SubSecTimeOriginal') or
        parse_timestamp_with_exif(path, metadata, 'DateTime', 'SubSecTime') or
        parse_timestamp_with_exif(path, metadata, 'EXIF DateTimeOriginal', 'EXIF SubSecTimeOriginal') or
        parse_timestamp_with_exif(path, metadata, 'EXIF DateTime', 'EXIF SubSecTime') or
        parse_timestamp_with_hachoir(metadata) or
        parse_timestamp_with_path(path) or
        parse_timestamp_with_stat(stat)
    )

def parse_timestamp_with_stat(stat):
    return datetime.datetime.fromtimestamp(stat.st_ctime)

def parse_timestamp_with_path(path):
    match = re.search(r'\b\d{8}-\d{6}\b', str(path))
    if match:
        return datetime.datetime.strptime(match.group(0), '%Y%m%d-%H%M%S')
    else:
        return None

def parse_timestamp_with_hachoir(metadata):
    try:
        return datetime.datetime.strptime(metadata['Creation date'], '%Y-%m-%d %H:%M:%S')
    except KeyError:
        return None

def parse_timestamp_with_exif(path, metadata, date, subsec):
    if path.suffix.lower() not in ['.jpg', '.jpeg', '.png', '.heic']: return

    try:
        value = '{}.{}'.format(metadata[date], metadata.get(subsec, 0))
        return datetime.datetime.strptime(value, '%Y:%m:%d %H:%M:%S.%f')
    except (ValueError, KeyError):
        return None

def parse_metadata_with_exifread(path):
    if path.suffix.lower() not in ['.jpg', '.jpeg', '.png', '.heic']: return

    with open(path, 'rb') as fd:
        return {key: str(value) for key, value in exifread.process_file(fd).items()}

def parse_metadata_with_pil(path):
    if path.suffix.lower() not in ['.jpg', '.jpeg', '.png', '.heic']: return

    try:
        exif = PIL.Image.open(path).getexif().items()
        result = {}
        for tag, value in exif:
            key = str(PIL.ExifTags.TAGS.get(tag))
            if type(value) == bytes:
                result[key] = base64.b64encode(value).decode('utf-8')
            else:
                result[key] = str(value)
        return result
    except PIL.UnidentifiedImageError:
        return {}

def parse_metadata_with_hachoir(path):
    try:
        parser = hachoir.parser.createParser(str(path))
        metadata = hachoir.metadata.extractMetadata(parser)
        return metadata.exportDictionary().get('Metadata', {})
    except:
        return {}

def parse_metadata_with_none(path):
    print("failed to parse metadata: ", path)
    return {}

def parse_metadata(path):
    return (
        parse_metadata_with_pil(path) or
        parse_metadata_with_exifread(path) or
        parse_metadata_with_hachoir(path) or
        parse_metadata_with_none(path)
    )

def parse_media(args, source):
    suffix = source.suffix.lower()

    if suffix not in ['.jpg', '.jpeg', '.png', '.mov', '.mp4', '.heic']:
        print('SKIP: ', source)
        return

    digest = parse_digest(source)
    metadata = parse_metadata(source)
    stat = source.stat()
    taken_at = parse_taken_at(metadata, source, stat)

    year = taken_at.strftime('%Y')
    month = taken_at.strftime('%m')
    sec = taken_at.strftime('%H%M%S')
    stem = '-'.join((sec, digest[:16]))

    path = args.output.joinpath(year, month, stem).with_suffix(suffix)

    return dict(
        name=source.name,
        stem=source.stem,
        extension=suffix,
        metadata=json.dumps(metadata),
        path=str(path),
        digest=digest,
        size=stat.st_size,
        taken_at=taken_at,
        source=source,
    )

def save_media(params):
    query = Photo.insert(params).on_conflict(conflict_target=[Photo.source], update=params)
    query.execute()

    return Photo.select().where(Photo.digest == params['digest']).execute()[0]

def input_iterator(args):
    for folder in args.input:
        folder = pathlib.Path(folder)
        for path in itertools.chain([folder], folder.glob(r'**\*')):
            if path.is_file():
                yield path

def main():
    parser = argparse.ArgumentParser(description='organize photos')
    parser.add_argument('input', nargs='+')
    parser.add_argument('--output', '-o', default=r'E:\Photos', type=pathlib.Path)
    args = parser.parse_args()

    db.connect()
    db.create_tables([Photo])

    #import logging
    #logger = logging.getLogger('peewee')
    #logger.addHandler(logging.StreamHandler())
    #logger.setLevel(logging.DEBUG)

    #hachoir.core.config.quiet = True

    pool = multiprocessing.Pool()

    count_total = 0
    size_total = 0
    for path in input_iterator(args):
        count_total += 1
        size_total += path.stat().st_size


    count_processed = 0
    size_processed = 0
    for path in input_iterator(args):
        count_processed += 1
        size_processed += path.stat().st_size

        result = parse_media(args, path)

        if result is None: continue

        save_media(result)

        print('mv {} {} {}/{} {}/{}'.format(
            result['source'],
            result['path'],
            count_processed,
            count_total,
            humanize.naturalsize(size_processed),
            humanize.naturalsize(size_total)
        ))

    photos = Photo.select().where(Photo.organized_at == None)

    #for parent in set(pathlib.Path(photo.path).parent for photo in photos):
    #    parent.mkdir(parents=True, exist_ok=True)

        #print('mv', photo.source, photo.path)

if __name__ == '__main__':
    main()
